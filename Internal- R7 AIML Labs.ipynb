{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R7_InternalLab_Questions_FMNIST_Simple_CNN_CIFAR_DATA_Augment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyfMmMnPJjvn",
        "colab_type": "text"
      },
      "source": [
        "## Train a simple convnet on the Fashion MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjcGOJhcJjvp",
        "colab_type": "text"
      },
      "source": [
        "In this, we will see how to deal with image data and train a convnet for image classification task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR0Pl2XjJjvq",
        "colab_type": "text"
      },
      "source": [
        "### Load the  `fashion_mnist`  dataset\n",
        "\n",
        "** Use keras.datasets to load the dataset **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr75v_UYJjvs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "e1a65daa-3648-48ab-c246-0f3e91f73711"
      },
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htuiNBd4J8Hk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "import pandas as pd\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTI42-0qJjvw",
        "colab_type": "text"
      },
      "source": [
        "### Find no.of samples are there in training and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2sf67VoJjvx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d77f877c-40bc-4ea1-91bd-02dfe56a45fb"
      },
      "source": [
        "print('x_train shape:',x_train.shape)\n",
        "print('y_train shape:',y_train.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28)\n",
            "y_train shape: (60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nmUJl1TKuun",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ab3df0e3-7232-4aa9-fec7-d4743abd064f"
      },
      "source": [
        "print('x_test shape:',x_test.shape)\n",
        "print('y_test shape:',y_test.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_test shape: (10000, 28, 28)\n",
            "y_test shape: (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WytT2eRnJjv4",
        "colab_type": "text"
      },
      "source": [
        "### Find dimensions of an image in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XycQGBSGJjv5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ce178282-8a29-4d9f-89f1-84b7b8b362a8"
      },
      "source": [
        "print(len(np.unique(y_train)))\n",
        "print(len(np.unique(y_test)))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jtdZ7RqJjv8",
        "colab_type": "text"
      },
      "source": [
        "### Convert train and test labels to one hot vectors\n",
        "\n",
        "** check `keras.utils.to_categorical()` **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAD3q5I6Jjv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = np_utils.to_categorical(y_train,10)\n",
        "y_test = np_utils.to_categorical(y_test,10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgHSCXy3JjwA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "04055fa7-a90b-4ef4-f808-b1157472295a"
      },
      "source": [
        "y_train"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 1.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJDehEaIORR-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "5c4ca5e6-f07c-41a8-b470-fdecb2a5d978"
      },
      "source": [
        "y_test"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xO5BRBzBJjwD",
        "colab_type": "text"
      },
      "source": [
        "### Normalize both the train and test image data from 0-255 to 0-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fUQpMHxJjwE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c8ed929-f2f1-4e5b-a6d5-8ef986d3f535"
      },
      "source": [
        "x_train[0].shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um2dqF3oO4Bb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d16f8cee-3853-4db1-f976-fc5c9b4a9573"
      },
      "source": [
        "x_test[0].shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Okwo_SB5JjwI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')\n",
        "#x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da5-DwgrJjwM",
        "colab_type": "text"
      },
      "source": [
        "### Reshape the data from 28x28 to 28x28x1 to match input dimensions in Conv2D layer in keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPGVQ-JJJjwN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFRRTJq8JjwQ",
        "colab_type": "text"
      },
      "source": [
        "### Import the necessary layers from keras to build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWTZYnKSJjwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Reshape\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras import backend as k \n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras import optimizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V__V38eaWGLE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import cifar10, mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Reshape\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C18AoS7eJjwU",
        "colab_type": "text"
      },
      "source": [
        "### Build a model \n",
        "\n",
        "** with 2 Conv layers having `32 3x3 filters` in both convolutions with `relu activations` and `flatten` before passing the feature map into 2 fully connected layers (or Dense Layers) having 128 and 10 neurons with `relu` and `softmax` activations respectively. Now, using `categorical_crossentropy` loss with `adam` optimizer train the model with early stopping `patience=5` and no.of `epochs=10`. **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtvlR4BXSwVp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UN11NYPZWq5b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 925
        },
        "outputId": "87abfb92-f6a2-4156-d081-7244e6829c24"
      },
      "source": [
        "\n",
        "    model1 = Sequential()\n",
        "\n",
        "    # 1st Conv Layer\n",
        "    model1.add(Convolution2D(32, 3, 3, input_shape=(28, 28, 1)))\n",
        "    model1.add(Activation('relu'))\n",
        "\n",
        "    # 2nd Conv Layer\n",
        "    model1.add(Convolution2D(32, 3, 3))\n",
        "    model1.add(Activation('relu'))\n",
        "\n",
        "    #flatten the 2nd layer\n",
        "    model1.add(Flatten())\n",
        "    model1.add(Dense(128))\n",
        "    model1.add(Activation('relu'))\n",
        "\n",
        "    # Prediction Layer\n",
        "    model1.add(Dense(10))\n",
        "    model1.add(Activation('softmax'))\n",
        "\n",
        "    # Optimize and train the model\n",
        "    model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    # Store Training Results\n",
        "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=10, verbose=1, mode='auto')\n",
        "    callback_list = [early_stopping]\n",
        "\n",
        "    # Train the model\n",
        "    model1.fit(x_train, y_train,nb_epoch=EPOCHS, \n",
        "              validation_data=(x_test, y_test), callbacks=callback_list)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "60000/60000 [==============================] - 28s 462us/step - loss: 0.3741 - acc: 0.8655 - val_loss: 0.2853 - val_acc: 0.8975\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 14s 228us/step - loss: 0.2318 - acc: 0.9150 - val_loss: 0.2629 - val_acc: 0.9031\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 13s 224us/step - loss: 0.1685 - acc: 0.9371 - val_loss: 0.2494 - val_acc: 0.9117\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 13s 223us/step - loss: 0.1174 - acc: 0.9553 - val_loss: 0.2718 - val_acc: 0.9133\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 13s 224us/step - loss: 0.0797 - acc: 0.9709 - val_loss: 0.3046 - val_acc: 0.9052\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 14s 226us/step - loss: 0.0554 - acc: 0.9798 - val_loss: 0.3423 - val_acc: 0.9093\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 13s 224us/step - loss: 0.0378 - acc: 0.9865 - val_loss: 0.4364 - val_acc: 0.9095\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 14s 228us/step - loss: 0.0303 - acc: 0.9892 - val_loss: 0.4293 - val_acc: 0.9141\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 13s 224us/step - loss: 0.0225 - acc: 0.9919 - val_loss: 0.4839 - val_acc: 0.9081\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 14s 225us/step - loss: 0.0205 - acc: 0.9928 - val_loss: 0.5453 - val_acc: 0.9094\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fda2d93ecf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaUT35RZa8Yd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4a5a1e1e-17c6-4f6b-adf0-07eb333e2b04"
      },
      "source": [
        "loss_and_metrics = model1.evaluate(x_test, y_test)\n",
        "print(loss_and_metrics)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 59us/step\n",
            "[0.5452946888677775, 0.9094]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_PDcJtvbG_4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "fb19b1c3-68c0-4e50-f52c-d9d51016f0c4"
      },
      "source": [
        "loss_and_metrics = model1.evaluate(x_train, y_train)\n",
        "print(loss_and_metrics)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 3s 55us/step\n",
            "[0.019851928316901832, 0.99285]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ju69vKdIJjwX",
        "colab_type": "text"
      },
      "source": [
        "### Now, to the above model add `max` pooling layer of `filter size 2x2` and `dropout` layer with `p=0.25` after the 2 conv layers and run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2hAP94vJjwY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "outputId": "e1ef7b27-e43b-45aa-8a10-5d47a405a4a9"
      },
      "source": [
        "# Define Model\n",
        "    model2 = Sequential()\n",
        "\n",
        "    # 1st Conv Layer\n",
        "    model2.add(Convolution2D(32, 3, 3, input_shape=(28, 28, 1)))\n",
        "    model2.add(Activation('relu'))\n",
        "    # 2nd Conv Layer\n",
        "    model2.add(Convolution2D(32, 3, 3))\n",
        "    model2.add(Activation('relu'))\n",
        "\n",
        "    #Max pooling\n",
        "    model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model2.add(Dropout(0.25))\n",
        "\n",
        "    #flatten the 2nd layer\n",
        "    model2.add(Flatten())\n",
        "    model2.add(Dense(128))\n",
        "    model2.add(Activation('relu'))\n",
        "    \n",
        "    #prediction layer\n",
        "    model2.add(Dense(10))\n",
        "    model2.add(Activation('softmax'))\n",
        "\n",
        "    #Optimize and train the model\n",
        "    model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    # Store Training Results\n",
        "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=10, verbose=1, mode='auto')\n",
        "    callback_list = [early_stopping]\n",
        "\n",
        "    # Train the model\n",
        "    model2.fit(x_train, y_train,nb_epoch=EPOCHS, \n",
        "              validation_data=(x_test, y_test), callbacks=callback_list)\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 11s 176us/step - loss: 0.3891 - acc: 0.8599 - val_loss: 0.3179 - val_acc: 0.8838\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 0.2575 - acc: 0.9046 - val_loss: 0.2563 - val_acc: 0.9048\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 10s 166us/step - loss: 0.2127 - acc: 0.9223 - val_loss: 0.2356 - val_acc: 0.9133\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 10s 166us/step - loss: 0.1789 - acc: 0.9336 - val_loss: 0.2309 - val_acc: 0.9165\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 10s 166us/step - loss: 0.1505 - acc: 0.9438 - val_loss: 0.2435 - val_acc: 0.9132\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 10s 166us/step - loss: 0.1292 - acc: 0.9522 - val_loss: 0.2176 - val_acc: 0.9234\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.1117 - acc: 0.9584 - val_loss: 0.2353 - val_acc: 0.9233\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 10s 166us/step - loss: 0.0925 - acc: 0.9649 - val_loss: 0.2449 - val_acc: 0.9243\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 10s 175us/step - loss: 0.0845 - acc: 0.9685 - val_loss: 0.2612 - val_acc: 0.9254\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0717 - acc: 0.9730 - val_loss: 0.2674 - val_acc: 0.9264\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd9c63859b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CWkLldDba9D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d192db65-48de-4dab-c117-2d9ea2bd2481"
      },
      "source": [
        "loss_and_metrics = model2.evaluate(x_train, y_train)\n",
        "print(loss_and_metrics)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 3s 54us/step\n",
            "[0.04070882189236581, 0.9863166666666666]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4szsEFVAbhnK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7c5f34f7-1817-4dec-cdc6-e52c5ae83575"
      },
      "source": [
        "loss_and_metrics = model2.evaluate(x_test, y_test)\n",
        "print(loss_and_metrics)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 58us/step\n",
            "[0.26742791670523586, 0.9264]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGTA3bfEJjwa",
        "colab_type": "text"
      },
      "source": [
        "### Now, to the above model, lets add Data Augmentation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6gX8n5SJjwb",
        "colab_type": "text"
      },
      "source": [
        "### Import the ImageDataGenrator from keras and fit the training images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cbz4uHBuJjwc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Nxa68FfbwBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This will do preprocessing and realtime data augmentation:\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "    samplewise_center=False,  # set each sample mean to 0\n",
        "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "    samplewise_std_normalization=False,  # divide each input by its std\n",
        "    zca_whitening=False,  # apply ZCA whitening\n",
        "    rotation_range=50,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
        "    height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
        "    horizontal_flip=False,  # randomly flip images\n",
        "    vertical_flip=False)  # randomly flip images\n",
        "\n",
        "# Prepare the generator\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl-8dOo7Jjwf",
        "colab_type": "text"
      },
      "source": [
        "#### Showing 5 versions of the first image in training dataset using image datagenerator.flow()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "DpI1_McYJjwg",
        "colab_type": "code",
        "outputId": "528d241c-9d16-4fb7-9843-f8004cbfb122",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "gen = datagen.flow(x_train[0:1], batch_size=1)\n",
        "for i in range(1, 6):\n",
        "    plt.subplot(1,5,i)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(gen.next().squeeze(), cmap='gray')\n",
        "    plt.plot()\n",
        "plt.show()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABICAYAAABV5CYrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/waW5UbTrX9hAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmPl5yE8Jjwm",
        "colab_type": "text"
      },
      "source": [
        "### Run the above model using fit_generator()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44ZnDdJYJjwn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "outputId": "5b36e164-b3c1-4da7-e116-258def5c9a9a"
      },
      "source": [
        "model2.fit_generator(datagen.flow(x_train, y_train,batch_size=32),\n",
        "                    samples_per_epoch=x_train.shape[0],\n",
        "                    nb_epoch=10,\n",
        "                    validation_data=(x_test, y_test), callbacks=callback_list)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "  12/1875 [..............................] - ETA: 20s - loss: 3.5148 - acc: 0.2917"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=(array([[[..., callbacks=[<keras.ca..., steps_per_epoch=1875, epochs=10)`\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.9238 - acc: 0.6649 - val_loss: 0.4524 - val_acc: 0.8346\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.6880 - acc: 0.7477 - val_loss: 0.4472 - val_acc: 0.8470\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.6283 - acc: 0.7698 - val_loss: 0.4077 - val_acc: 0.8519\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.5882 - acc: 0.7832 - val_loss: 0.4236 - val_acc: 0.8480\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.5641 - acc: 0.7922 - val_loss: 0.4053 - val_acc: 0.8511\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.5454 - acc: 0.7986 - val_loss: 0.3975 - val_acc: 0.8572\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.5281 - acc: 0.8081 - val_loss: 0.4125 - val_acc: 0.8582\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.5106 - acc: 0.8099 - val_loss: 0.3984 - val_acc: 0.8582\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.5024 - acc: 0.8149 - val_loss: 0.4094 - val_acc: 0.8564\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.4905 - acc: 0.8182 - val_loss: 0.3843 - val_acc: 0.8608\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fda20026a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwQQW5iOJjwq",
        "colab_type": "text"
      },
      "source": [
        "###  Report the final train and validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1SrtBEPJjwq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c5aeff80-49e3-4eca-aa57-8ffd9fdebff5"
      },
      "source": [
        "loss_and_metrics = model2.evaluate(x_train, y_train)\n",
        "print(loss_and_metrics)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 3s 56us/step\n",
            "[0.35391153378486634, 0.8675833333333334]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBwVWNQC2qZD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "41de1fc5-16f4-41c9-9b06-738927045f8d"
      },
      "source": [
        "loss_and_metrics = model2.evaluate(x_test, y_test)\n",
        "print(loss_and_metrics)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 57us/step\n",
            "[0.3843107450723648, 0.8608]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KXqmUDW2rM1",
        "colab_type": "text"
      },
      "source": [
        "## **DATA AUGMENTATION ON CIFAR10 DATASET**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mja6OgQ3L18",
        "colab_type": "text"
      },
      "source": [
        "One of the best ways to improve the performance of a Deep Learning model is to add more data to the training set. Aside from gathering more instances from the wild that are representative of the distinction task, we want to develop a set of methods that enhance the data we already have. There are many ways to augment existing datasets and produce more robust models. In the image domain, these are done to utilize the full power of the convolutional neural network, which is able to capture translational invariance. This translational invariance is what makes image recognition such a difficult task in the first place. You want the dataset to be representative of the many different positions, angles, lightings, and miscellaneous distortions that are of interest to the vision task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HzVTPUM3WZJ",
        "colab_type": "text"
      },
      "source": [
        "### **Import neessary libraries for data augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPM558TX4KMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6hicLwP4SqY",
        "colab_type": "text"
      },
      "source": [
        "### **Load CIFAR10 dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ1WzrXd4WNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import cifar10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9Pht1ggHuiT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "0dd9a8e5-4003-45ee-a87f-2984468e1928"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwImTSkhkc_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4593d371-1e05-45f5-f1be-2fb5551c4a3a"
      },
      "source": [
        "x_train[0].shape"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7fQYPbokeWd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca16ac9d-2b25-4dc6-b222-8588b51740b1"
      },
      "source": [
        "x_test[0].shape"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6lYVEGQkiwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], 32, 32, 3).astype('float32')\n",
        "x_test = x_test.reshape(x_test.shape[0], 32, 32, 3).astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JN3vYYhK4W0u",
        "colab_type": "text"
      },
      "source": [
        "### **Create a data_gen funtion to genererator with image rotation,shifting image horizontally and vertically with random flip horizontally.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJbekTKi4cmM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This will do preprocessing and realtime data augmentation:\n",
        "data_gen = ImageDataGenerator(\n",
        "    rotation_range=50,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    horizontal_flip=True,  # randomly flip images\n",
        "    vertical_flip=True,\n",
        "    width_shift_range=0.2,  \n",
        "    height_shift_range=0.2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-SLtUhC4dK2",
        "colab_type": "text"
      },
      "source": [
        "### **Prepare/fit the generator.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSw8Bv2_4hb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_gen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYyF-P8O4jQ8",
        "colab_type": "text"
      },
      "source": [
        "### **Generate 5 images for 1 of the image of CIFAR10 train dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXug4z234mwQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "d1f80e0e-2126-47fc-acb4-a68dc952d29a"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "gen = data_gen.flow(x_train[0:1], batch_size=1)\n",
        "for i in range(1, 6):\n",
        "    plt.subplot(1,5,i)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(gen.next().squeeze(), cmap='gray')\n",
        "    plt.plot()\n",
        "plt.show()"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABICAYAAABV5CYrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\neYPSbrqttNJKK29Q2k23lVZaaeUNyr8HonOV06eQf9MAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}